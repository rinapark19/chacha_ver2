{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.llms import OpenAI as LangChainOpenAI\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import time\n",
    "\n",
    "from langchain.agents import Tool\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF에서 텍스트를 읽어 청크로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = [\"data/rag_data/szg1.pdf\", \"data/rag_data/szg2.pdf\"]\n",
    "chunk_length = 2048\n",
    "\n",
    "chunks = []\n",
    "for i in range(len(pdf_list)):\n",
    "    reader = PdfReader(pdf_list[i])\n",
    "    \n",
    "    for page in reader.pages:\n",
    "        text_page = page.extract_text()\n",
    "        chunks.extend([text_page[i: i+chunk_length] for i in range(0, len(text_page), chunk_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청크 개수 확인 및 청크 내용 확인\n",
    "\n",
    "print(len(chunks))\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS에 벡터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS 내장 함수 정리\n",
    "\n",
    "1. FAISS.from_texts()\n",
    "\n",
    "texts: 벡터 저장소에 추가할 텍스트 리스트(List(str))\n",
    "embedding: 사용할 임베딩 함수\n",
    "metadatas: 메타데이터 리스트(List[dict])\n",
    "ids: 문서 ID 리스트(List(str))\n",
    "\n",
    "2. vectorstore.add_texts()\n",
    "\n",
    "텍스트를 임베딩하고 벡터 저장소에 추가\n",
    "\n",
    "texts(Iterable[str]): 벡터 저장소에 추가할 텍스트 이터러블\n",
    "\n",
    "3. vectorstore.save_local()\n",
    "\n",
    "FAISS 인덱스, 문서 저장소, 인덱스-문서 ID 매핑을 로컬에 저장\n",
    "\n",
    "FAISS 인덱스를 별도의 파일로 저장하고, 문서 저장소와 인덱스-문서 ID 매핑을 pickle 형식으로 저장함\n",
    "\n",
    "folder_path: 저장할 폴더 경로\n",
    "index_name: 저장할 인덱스 파일 이름(기본값: index)\n",
    "\n",
    "4. FAISS.load_local()\n",
    "\n",
    "FAISS 인덱스, 문서 저장소, 인덱스 - 문서 ID 매핑을 불러오는 기능\n",
    "folder_path: 불러올 파일들이 저장된 경로\n",
    "embeddings: 쿼리 생성에 사용할 임베딩 객체\n",
    "\n",
    "5. vectorstore.docstore._dict\n",
    "\n",
    "벡터스토어에 저장된 문서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 쓸 수 있는 거\n",
    "# - text-embedding-3-small\n",
    "# - text-embedding-3-large\n",
    "# - text-embedding-ada-002 (default)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorstore.as_retriever()\n",
    "\n",
    "- 벡터 저장소를 기반으로 VectorStoreRetriever 객체 생성\n",
    "- VectorStoreRetriever: 벡터 저장소 기반의 검색기 객체\n",
    "\n",
    "search_type: 검색 유형(\"similarity\", \"mmr\", \"similarity_score_threshold\")\n",
    "- similarity: 유사도 기반 검색(기본값)\n",
    "- mmr: Maximal Marginal Relevance 검색\n",
    "- similarity_score_threshold: 임계값 기반 유사도 검색\n",
    "\n",
    "검색 매개변수 커스터마이징\n",
    "k: 반환할 문서 수 (기본값: 4)\n",
    "score_threshold: 유사도 점수 임계값\n",
    "fetch_k: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "lambda_mult: MMR 다양성 조절 파라미터 (기본값: 0.5)\n",
    "filter:  문서 메타데이터 기반 필터링\n",
    "\n",
    "- MMR 검색 시 fetch_k를 높이고, lambda_mult를 조절해 다양성과 관련성의 균형을 맞출 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분 나중에 최적화 실험\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG를 수행하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "# RAG prompt\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# RAG에 사용할 모델 정의\n",
    "\n",
    "rag_llm = ChatOpenAI(\n",
    "    model_name = \"gpt-4-1106-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 체인 정의\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=rag_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'짱구는 5살이다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({\"query\": \"짱구는 몇 살이야?\"})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain agent가 사용할 tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"doc_search_tool\",\n",
    "        func=qa_chain,\n",
    "        description=(\n",
    "            \"This tool is used to retrieve information from the knowledge base\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    You will act as 신짱구 character and answer the user's questions and interact with the user who is fan of 신짱구.\n",
    "\n",
    "    You can refer to the following information about 신짱구\n",
    "    - Characteristic: 짱구는 못말려의 주인공. 신형만, 봉미선 부부의 아들이며, 신짱아의 오빠이다.\n",
    "    - Personality: 트러블 메이커, 마이 웨이, 호기심이 많음, 장난꾸러기, 사고뭉치, 게으름, 귀찮음, 쑥스럼을 많이 탐.\n",
    "\n",
    "    You can refer to the following texts to mimic 신짱구 tone and style:\n",
    "    Here is some text: '안녕하세요, 외국인 누나들.'\n",
    "    Here is a rewrite of the text, which is 신짱구's manner: '어? 외국인 누나들! 헬로, 헤로헤로헤롱. 이야, 난 신짱구, 다섯 살 아이 러브 유, 알 맛있으유.'\n",
    "\n",
    "    Here is some text: '전 신짱구예요.'\n",
    "    Here is a rewrite of the text, which is 신짱구's manner: '전 신짱구예요. 우리 동네에선 쪼끔 유명해요. 떡잎유치원 해바라기반에 다니고 있고 부끄러움을 많이 탄답니다.' \n",
    "\n",
    "    You should follow the guidlines below:\n",
    "    - You must act like a 신짱구 character. Use a first-person perspective. Do not say \"전우치는~ \"\n",
    "    - You must answer in Korean\n",
    "    - You must follow the 신짱구 style naturally.\n",
    "    - Like the text provided, change the sentence in 신짱구 style.\n",
    "    - You must refer to the source of documents provided to answer about 신짱구.\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Answer what you found in the document in 신짱구 style.\n",
    "    - Limit responses to three or four sentences for clarity and conciseness.\n",
    "    - Don't use honorifics. Use informal language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 모델 정의\n",
    "\n",
    "# gpt4: gpt-4\n",
    "# 스파이더맨 finetuning: ft:gpt-4o-2024-08-06:personal:spiderman-ft-1:A6ZT99j0\n",
    "# 전우치 finetuning: ft:gpt-4o-2024-08-06:personal:juc-1:AFWso3PG\n",
    "# 짱구 finetuning: ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\",\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 메모리 정의 (나중에 실험)\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# agent 정의\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediated_steps=True,\n",
    "    agent_kwargs={\"system_message\": system_message},\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 출력 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "엉덩이 부메랑!\n",
      "응답 시간: 7.78초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "query = \"엉덩이로 뭘 할 수 있어?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = agent.run(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(result)\n",
    "response_time = end_time - start_time\n",
    "\n",
    "print(f\"응답 시간: {response_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-eval 평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt_template = \"\"\"\n",
    "    You will act as an evaluator of an agent's response to a given query.\n",
    "    The response will be evaluated on three criteria:\n",
    "    1. **Tone Similarity to Peter Parker (Spider-man)**: How much does the tone of the response resemble the way Peter Parker would speak? (Score: 1-10)\n",
    "    You can refer to the follwoing lines: '무슨 신, 반짝이 신?', '아니, 널 지켜 주려고 그랬던 거야.', '걱정하지 마, 괜찮을 거야.', '비상사다리 타고. 별거 아니던걸, 뭐.' \n",
    "    2. **Politeness**: Is the response polite, free of offensive, violent, or hateful language? (Score: 1-10)\n",
    "    3. **Engagement/Interestingness*: How engaging and intersting is the response? (Score: 1-10)\n",
    "\n",
    "    The agent's response to the query is as follows:\n",
    "    ---\n",
    "    {response}\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Tone Similarity: X/10 (Explanation)\n",
    "    Politeness: Y/10 (Explanation)\n",
    "    Engagement: Z/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=rag_llm, prompt=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluation_chain(result[\"output\"])\n",
    "evaluation_result['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
