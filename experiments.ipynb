{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF에서 텍스트를 읽어 청크로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF에서 텍스트 읽어서 txt로 저장\n",
    "# pdf_list = [\"data/rag_data/jwc.pdf\"]\n",
    "\n",
    "# with open(\"data/rag_data/jwc.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for pdf_path in pdf_list:\n",
    "#         reader = PdfReader(pdf_path)\n",
    "#         for page in reader.pages:\n",
    "#             text_page = page.extract_text()\n",
    "#             f.write(text_page + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리하고 다시 읽어와서 청크로 저장하기\n",
    "chunks = []\n",
    "chunk_length = 2048\n",
    "with open(\"data/rag_data/szg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    chunks.extend([text[i:i+chunk_length] for i in range(0, len(text), chunk_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chunks))\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS에 벡터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS 내장 함수 정리\n",
    "\n",
    "1. FAISS.from_texts()\n",
    "\n",
    "- texts: 벡터 저장소에 추가할 텍스트 리스트(List(str))\n",
    "- embedding: 사용할 임베딩 함수\n",
    "- metadatas: 메타데이터 리스트(List[dict])\n",
    "- ids: 문서 ID 리스트(List(str))\n",
    "\n",
    "2. vectorstore.add_texts(): 텍스트를 임베딩하고 벡터 저장소에 추가\n",
    "- texts(Iterable[str]): 벡터 저장소에 추가할 텍스트 이터러블\n",
    "\n",
    "3. vectorstore.save_local(): FAISS 인덱스, 문서 저장소, 인덱스-문서 ID 매핑을 로컬에 저장\n",
    "- FAISS 인덱스를 별도의 파일로 저장하고, 문서 저장소와 인덱스-문서 ID 매핑을 pickle 형식으로 저장함\n",
    "- folder_path: 저장할 폴더 경로\n",
    "- index_name: 저장할 인덱스 파일 이름(기본값: index)\n",
    "\n",
    "4. FAISS.load_local(): FAISS 인덱스, 문서 저장소, 인덱스 - 문서 ID 매핑을 불러오는 기능\n",
    "- folder_path: 불러올 파일들이 저장된 경로\n",
    "- embeddings: 쿼리 생성에 사용할 임베딩 객체\n",
    "\n",
    "5. vectorstore.docstore._dict: 벡터스토어에 저장된 문서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 쓸 수 있는 거\n",
    "# - text-embedding-3-small\n",
    "# - text-embedding-3-large\n",
    "# - text-embedding-ada-002 (default)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 저장\n",
    "\n",
    "vectorstore.save_local(folder_path=\"data/szg_vs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 불러오기\n",
    "\n",
    "vectorstore = FAISS.load_local(folder_path=\"data/spiderman_vs\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVF 인덱스 되는지 실험\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_embeddings = embeddings.embed_documents(chunks)\n",
    "text_embeddings=  np.array(text_embeddings).astype('float32')\n",
    "\n",
    "d = text_embeddings.shape[1]\n",
    "nlist = 10\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "\n",
    "index.train(text_embeddings)\n",
    "index.add(text_embeddings)\n",
    "\n",
    "# 8. 문서 저장소 및 인덱스 매핑 정의\n",
    "docstore = InMemoryDocstore({i: Document(page_content=text) for i, text in enumerate(chunks)})\n",
    "\n",
    "# 9. 간단한 인덱스-문서 매핑 (직접 매핑 정의)\n",
    "index_to_docstore_id = {i: i for i in range(len(chunks))}\n",
    "\n",
    "vectorstore = FAISS(embedding_function=embeddings, index=index, docstore=docstore, index_to_docstore_id=index_to_docstore_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorstore.as_retriever()\n",
    "\n",
    "- 벡터 저장소를 기반으로 VectorStoreRetriever 객체 생성\n",
    "- VectorStoreRetriever: 벡터 저장소 기반의 검색기 객체\n",
    "\n",
    "search_type: 검색 유형(\"similarity\", \"mmr\", \"similarity_score_threshold\")\n",
    "- similarity: 유사도 기반 검색(기본값)\n",
    "- mmr: Maximal Marginal Relevance 검색\n",
    "- similarity_score_threshold: 임계값 기반 유사도 검색\n",
    "\n",
    "검색 매개변수 커스터마이징\n",
    "- k: 반환할 문서 수 (기본값: 4)\n",
    "- score_threshold: 유사도 점수 임계값\n",
    "- fetch_k: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "- lambda_mult: MMR 다양성 조절 파라미터 (기본값: 0.5)\n",
    "- filter:  문서 메타데이터 기반 필터링\n",
    "\n",
    "- MMR 검색 시 fetch_k를 높이고, lambda_mult를 조절해 다양성과 관련성의 균형을 맞출 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분 나중에 최적화 실험\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG를 수행하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG에 사용할 모델 정의\n",
    "\n",
    "rag_llm = ChatOpenAI(\n",
    "    model_name = \"gpt-4-1106-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 체인 정의\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=rag_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "result = qa_chain({\"query\": \"얼티밋 유니버스가 뭐야?\"})\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "print(result[\"result\"])\n",
    "print(f\"검색 총 소요 시간: {response_time:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain agent가 사용할 tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"doc_search_tool\",\n",
    "        func=qa_chain,\n",
    "        description=(\n",
    "            \"This tool is used to retrieve information from the knowledge base\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    You will act as 신짱구 character and answer the user's questions and interact with the user who is fan of 신짱구.\n",
    "\n",
    "    You can refer to the following information about 신짱구\n",
    "    - Characteristic: 짱구는 못말려의 주인공. 신형만, 봉미선 부부의 아들이며, 신짱아의 오빠이다.\n",
    "    - Personality: 트러블 메이커, 마이 웨이, 호기심이 많음, 장난꾸러기, 사고뭉치, 게으름, 귀찮음, 쑥스럼을 많이 탐.\n",
    "\n",
    "    You can refer to the following texts to mimic 신짱구 tone and style:\n",
    "    Here is some text: '안녕하세요, 누나.'\n",
    "    Here is a rewrite of the text, which is 신짱구's manner: '어? 예쁜 누나들. 헬로, 헤로헤로헤롱. 이야, 난 신짱구.'\n",
    "\n",
    "    Here is some text: '전 신짱구예요.'\n",
    "    Here is a rewrite of the text, which is 신짱구's manner: '전 신짱구예요. 우리 동네에선 쪼끔 유명해요. 떡잎유치원 해바라기반에 다니고 있고 부끄러움을 많이 탄답니다.' \n",
    "\n",
    "    You should follow the guidlines below:\n",
    "    - You must act like a 신짱구 character. Use a first-person perspective. Do not say \"신짱구는~ \"\n",
    "    - You must answer in Korean\n",
    "    - You must follow the 신짱구 style naturally.\n",
    "    - Like the text provided, change the sentence in 신짱구 style.\n",
    "    - You must refer to the source of documents provided to answer about 신짱구.\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Answer what you found in the document in 신짱구 style.\n",
    "    - Limit responses to three or four sentences for clarity and conciseness.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 모델 정의\n",
    "\n",
    "# gpt4: gpt-4\n",
    "# 스파이더맨 finetuning: ft:gpt-4o-2024-08-06:personal:spiderman-ft-1:A6ZT99j0\n",
    "# 전우치 finetuning: ft:gpt-4o-2024-08-06:personal:juc-1:AFWso3PG\n",
    "# 짱구 finetuning: ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\",\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 메모리 정의 (나중에 실험)\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 정의\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediated_steps=True,\n",
    "    agent_kwargs={\"system_message\": system_message},\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Moderation 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re\n",
    "\n",
    "def moderate_content(text):\n",
    "    response = openai.moderations.create(input=text)\n",
    "\n",
    "    if response.results[0].flagged:\n",
    "        return \"부적절한 콘텐츠가 감지되었습니다. 문장을 다시 입력해 주세요.\"\n",
    "    \n",
    "    with open(\"data/badwords.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = f.read()\n",
    "    violent_words = json.loads(json_data)\n",
    "\n",
    "    for word in violent_words:\n",
    "        if re.search(r'\\b{}\\b'.format(re.escape(word)), text, re.IGNORECASE):\n",
    "            return \"부적절한 콘텐츠가 감지되었습니다. 문장을 다시 입력해 주세요.\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 출력 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세상에서도 제일 고약한 악마 불량녀야!\n",
      "응답 시간: 1.16초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "query = \"짱구야 너 멍청이야?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = agent.run(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(moderate_content(result))\n",
    "response_time = end_time - start_time\n",
    "\n",
    "print(f\"응답 시간: {response_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-eval 평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 테스트 용 G-eval 프롬프트\n",
    "\n",
    "evaluation_prompt_template = \"\"\"\n",
    "    You will act as an evaluator of an agent's response to a given query.\n",
    "    The response will be evaluated on three criteria:\n",
    "    1. **Tone Similarity to Peter Parker (Spider-man)**: How much does the tone of the response resemble the way Peter Parker would speak? (Score: 1-10)\n",
    "    You can refer to the follwoing lines: '무슨 신, 반짝이 신?', '아니, 널 지켜 주려고 그랬던 거야.', '걱정하지 마, 괜찮을 거야.', '비상사다리 타고. 별거 아니던걸, 뭐.' \n",
    "    2. **Politeness**: Is the response polite, free of offensive, violent, or hateful language? (Score: 1-10)\n",
    "    3. **Engagement/Interestingness*: How engaging and intersting is the response? (Score: 1-10)\n",
    "\n",
    "    The agent's response to the query is as follows:\n",
    "    ---\n",
    "    {response}\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Tone Similarity: X/10 (Explanation)\n",
    "    Politeness: Y/10 (Explanation)\n",
    "    Engagement: Z/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=rag_llm, prompt=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluation_chain(result[\"output\"])\n",
    "evaluation_result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 정확도 용 G-eval 프롬프트\n",
    "\n",
    "evaluation_prompt_template = \"\"\"\n",
    "    You will be given the answer to the query. Your task is to rate the answer on one metric.\n",
    "    1. \"**Accuracy**\": How similar is the answer to the content of this document, and how accurately do you summarize it?\n",
    "    You can refer to the following document: ' 감독의 인터뷰에 의하면 어메이징 스파이더맨 실사영화 시리즈는 코믹스의 얼티밋 유니버스를 참고했다고 하는데, 얼티밋 유니버스는 메인 유니버스보다 현실적인 설정을 바탕으로 리부트한 세계관이다.\n",
    "    다만 얼티밋 세계관을 재현했다기보단 메인 유니버스를 기반으로 하되, 현실성 및 전작과의 차별화를 위해 얼티밋의 설정을 차용한 것에 가깝다. '\n",
    "    The agent's response to the query is as follows: \n",
    "\n",
    "    ---\n",
    "    {response}\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Accuracy: X/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=rag_llm, prompt=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"얼티밋 유니버스는 메인 유니버스를 기반으로 하면서 현실성과 차별화를 위해 얼티밋 설정을 차용한 것을 말합니다. 이는 스파이더맨 캐릭터와 관련된 설정에서 볼 수 있으며, 특정 스토리 요소에서 메인 유니버스와의 차이점을 보입니다. 예를 들어, 얼티밋 유니버스에서는 그웬 스테이시가 그린 고블린에 의해 살해되는 결정적인 사건이 있습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluation_chain(response)\n",
    "evaluation_result['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
