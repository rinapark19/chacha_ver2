{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.llms import OpenAI as LangChainOpenAI\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import time\n",
    "\n",
    "from langchain.agents import Tool\n",
    "\n",
    "import faiss\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF에서 텍스트를 읽어 청크로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = [\"data/rag_data/spiderman1.pdf\", \"data/rag_data/spiderman2.pdf\"]\n",
    "chunk_length = 2048\n",
    "\n",
    "chunks = []\n",
    "for i in range(len(pdf_list)):\n",
    "    reader = PdfReader(pdf_list[i])\n",
    "    \n",
    "    for page in reader.pages:\n",
    "        text_page = page.extract_text()\n",
    "        chunks.extend([text_page[i: i+chunk_length] for i in range(0, len(text_page), chunk_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "최근 변경 최근 토론\n",
      "어메이징  스파이더맨  실사영화  시리즈의 등장인물\n",
      "스파이더맨\n",
      "Spider -Man스파이더맨 ( 어메이징  스파이더맨  실사영화  시리\n",
      "즈)\n",
      "최근 수정  시각 : 2024-06-23 22:49:30\n",
      "  스파이더맨  트릴로지의  스파이더맨에  대한  내용은  스파이더맨 ( 스파이더맨  트릴로지 ) 문서를, 마블  시\n",
      "네마틱  유니버스의  스파이더맨에  대한  내용은  스파이더맨 ( 마블  시네마틱  유니버스 ) 문서를 참고하십시오 .\n",
      "스파이더맨  관련  틀\n",
      "[ 펼치기  · 접기  ]특수 기능\n",
      "여기에서  검색\n",
      "편집 요청 토론 역사\n",
      "분류: 피터 파커어메이징  스파이더맨  실사영화  시리즈 / 등장인물스파이더맨 ( 마블  시네마틱  유니버스 )…\n",
      "마블시네마틱 유니버 평행세계의 인물파이더맨 웨이 홈 장인물더 보기\n",
      "29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 청크 개수 확인 및 청크 내용 확인\n",
    "\n",
    "print(len(chunks))\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF에서 텍스트 읽어서 txt로 저장\n",
    "pdf_list = [\"data/rag_data/spiderman1.pdf\", \"data/rag_data/spiderman2.pdf\"]\n",
    "\n",
    "with open(\"data/rag_data/spiderman.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for pdf_path in pdf_list:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        for page in reader.pages:\n",
    "            text_page = page.extract_text()\n",
    "            f.write(text_page + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리하고 다시 읽어와서 청크로 저장하기\n",
    "chunks = []\n",
    "chunk_length = 2048\n",
    "with open(\"data/rag_data/spiderman.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    chunks.extend([text[i:i+chunk_length] for i in range(0, len(text), chunk_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "어메이징  스파이더맨  실사영화  시리즈의 등장인물 스파이더맨\n",
      "Spider -Man스파이더맨 ( 어메이징  스파이더맨  실사영화  시리즈)\n",
      "스파이더맨 : 노  웨이  홈\n",
      "본명 피터 벤저민  파커\n",
      "Peter Benjamin Parker\n",
      "이명 스파이더맨\n",
      "Spider -Man\n",
      "피터 3\n",
      "Peter-Three\n",
      "어메이징  스파이더맨\n",
      "Amazing Spider-Man\n",
      "종족 인간 (강화인간)\n",
      "국적 미국\n",
      "성별 남성\n",
      "가족 관계벤 파커 (숙부)\n",
      "메이 파커 (숙모)\n",
      "리처드  파커 (아버지)\n",
      "메리 파커  (어머니)\n",
      "등장 영화〈어메이징  스파이더맨〉\n",
      "〈어메이징  스파이더맨  2〉\n",
      "〈스파이더맨 : 노  웨이  홈〉\n",
      "〈스파이더맨 : 어크로스  더  유니버스〉 (카메오)\n",
      "담당 배우 앤드류  가필드\n",
      "담당 성우 정재헌\n",
      "마에노  토모아키\n",
      "스파이더맨 : 노  웨이  홈  - 어메이징  피터  #3\n",
      "어메이징  스파이더맨  실사영화  시리즈의 스파이더맨. 담당  배우는  앤드류  가필드. 1편의  아역  배우는  맥스\n",
      "찰스가  담당했다.\n",
      "슈트 디자인, 캐릭터성  등에서  상당한  리파인이  가해진  트릴로지와  MCU 스파이더맨에  비해  코믹스  속  어메\n",
      "이징 스파이더맨 을 최대한  실사적으로  묘사한  것이  특징. 웹  슈터에  독자적인  소프트웨어를  집어넣거나  실\n",
      "험을 통해  여러  발명을  하는  등, 스파이더맨  코믹스  특유의  SF 감성을  드러내는  장면이  많다. 거기에  더해  유\n",
      "쾌한 면모  및  가족에  대한  사랑  같은  장점부터, 우유부단한  면모와  불행으로  주변  인물을  잃고  고통받는  등\n",
      "원작의  피터를  연상케  하는  모습이  많다. 다만  피터의  여러  캐릭터성  중  한  가지에  초점을  맞춘  다른  두  시리\n",
      "즈에 비하면  얕고  넓게  다룬다는  느낌이  강하며, 이  때문인지  각각  책임감과  성장이라는  테마가  확고한  트릴\n",
      "로지와  MCU 스파이더맨에  비해  시리즈  전체를  관통하는  테마가  애매한  편이다. 대신  영화의  훌륭한  연출력\n",
      "과 액션신  퀄리티로  인한  비주얼이  많이  화자된다.\n",
      "원작의  스파이더맨의  특성을  닮아  항상  입을  쉬지  않으며  악당들을  제압한다. 1 편  당시엔  능력을  얻은지  얼\n",
      "마 안된  상태인데  목숨  내놓고  싸워야  하는  상황이라  그런지  아예  만만한  상대이거나  가끔  빈틈을  보였을때\n",
      "겨우 한마디씩  던지는  모습을  보였던  편이지만 능력에  숙련도가  생겨  심리적인  여유가  생긴듯한  2 편에선\n",
      "그야말로  상대를  가리지  않고  입을  털고  도발하면서  싸우는  모습을  보인다. 특히  이  촉새  기질은  다른  스파\n",
      "이더맨들과  비교해도  독보적인  수준으로, 노 웨이  홈에서 세  명이  같이  등장했을  때  묵묵히  싸우는  다른  두\n",
      "피터와는  달리  일렉트로에게  본명인  맥스를  부르며  보고  싶었다며  반갑게  인사하고  도망치거나, 리저드에\n",
      "게는 “안녕하세요, 코너스  박사님!” 이라며  멱살  잡힌  상황에서도  쉴  새  없이  떠들어대는  등  유쾌한  캐릭터성\n",
      "을 잘  보여준다.\n",
      "다른 스파이더맨들과  같이  스파이더맨일때의  모습과  피터  파커의  모습이  차이가  나며, 작중에서  상실과  풍\n",
      "파도 직접적으로  많이  겪는다. 그러나  그것을  해결하고  헤쳐나가는  이후의  과정을  그릴  영화들이  흥행부진\n",
      "으로 중도에  끝이  나버렸고, 인간관계와  멘탈적인  문제들도  중과부적으로  끝난  상태가  되었다. 그로인해  노\n",
      "웨이 홈  등의  후속작에선  안그래도  어둡고  겉도는  성격이  더욱  심해져  나약하게  보일정도로  묘사된다. 이렇\n",
      "게 성격이  변한  사유는  어린  시절부터  오스코프와  연루되며  집안이  시끄러워지며  생긴  부모님의  부재가  원\n",
      "인. 어떻게든  나아가려는  모습을  볼때  멘탈이  나약하진  않으나, 지속적인  갈등과  그로인한  상처  때문에  죄책\n",
      "감과 트라우마가  쌓여  2 편  이후부턴  항상  PTSD 환자처럼  보일  정도로  시달리는  모습을  보인다.\n",
      "이와 별개로  성격  자체는  꽤  당돌했던  편.\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS에 벡터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS 내장 함수 정리\n",
    "\n",
    "1. FAISS.from_texts()\n",
    "\n",
    "- texts: 벡터 저장소에 추가할 텍스트 리스트(List(str))\n",
    "- embedding: 사용할 임베딩 함수\n",
    "- metadatas: 메타데이터 리스트(List[dict])\n",
    "- ids: 문서 ID 리스트(List(str))\n",
    "\n",
    "2. vectorstore.add_texts(): 텍스트를 임베딩하고 벡터 저장소에 추가\n",
    "- texts(Iterable[str]): 벡터 저장소에 추가할 텍스트 이터러블\n",
    "\n",
    "3. vectorstore.save_local(): FAISS 인덱스, 문서 저장소, 인덱스-문서 ID 매핑을 로컬에 저장\n",
    "- FAISS 인덱스를 별도의 파일로 저장하고, 문서 저장소와 인덱스-문서 ID 매핑을 pickle 형식으로 저장함\n",
    "- folder_path: 저장할 폴더 경로\n",
    "- index_name: 저장할 인덱스 파일 이름(기본값: index)\n",
    "\n",
    "4. FAISS.load_local(): FAISS 인덱스, 문서 저장소, 인덱스 - 문서 ID 매핑을 불러오는 기능\n",
    "- folder_path: 불러올 파일들이 저장된 경로\n",
    "- embeddings: 쿼리 생성에 사용할 임베딩 객체\n",
    "\n",
    "5. vectorstore.docstore._dict: 벡터스토어에 저장된 문서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 쓸 수 있는 거\n",
    "# - text-embedding-3-small\n",
    "# - text-embedding-3-large\n",
    "# - text-embedding-ada-002 (default)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 인덱스를 사용하기\n",
    "\n",
    "embedding_vectors = [embeddings.embed_documents(text) for text in chunks]\n",
    "\n",
    "# 임베딩 벡터를 패딩 하고 넘파이 배열로 변환\n",
    "lengths = [len(vec) for vec in embedding_vectors]\n",
    "max_length = max(lengths)\n",
    "\n",
    "padded_vectors = []\n",
    "for vec in embedding_vectors:\n",
    "    padded_vec = np.pad(vec, (0, max_length - len(vec)), \"constant\", constant_values=0)\n",
    "    padded_vectors.append(padded_vec)\n",
    "\n",
    "embedding_vectors_np = np.array(padded_vectors, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (28, 2048) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embedding_vectors_np \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 인덱스 훈련\u001b[39;00m\n\u001b[0;32m      4\u001b[0m index\u001b[38;5;241m.\u001b[39mtrain(embedding_vectors_np)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (28, 2048) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "d = embedding_vectors_np.shape[1]\n",
    "\n",
    "# IVFFlat index 만들기\n",
    "nlist = 100 # IVF의 클러스터 수, 적절하게 조정해야 함\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# 인덱스 훈련\n",
    "index.train(embedding_vectors_np)\n",
    "\n",
    "# 벡터 추가\n",
    "index.add(embedding_vectors_np)\n",
    "\n",
    "# 랭체인 벡터스토어로 저장\n",
    "vectorstore = FAISS(embedding_vectors_np, chunks, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorstore.as_retriever()\n",
    "\n",
    "- 벡터 저장소를 기반으로 VectorStoreRetriever 객체 생성\n",
    "- VectorStoreRetriever: 벡터 저장소 기반의 검색기 객체\n",
    "\n",
    "search_type: 검색 유형(\"similarity\", \"mmr\", \"similarity_score_threshold\")\n",
    "- similarity: 유사도 기반 검색(기본값)\n",
    "- mmr: Maximal Marginal Relevance 검색\n",
    "- similarity_score_threshold: 임계값 기반 유사도 검색\n",
    "\n",
    "검색 매개변수 커스터마이징\n",
    "- k: 반환할 문서 수 (기본값: 4)\n",
    "- score_threshold: 유사도 점수 임계값\n",
    "- fetch_k: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "- lambda_mult: MMR 다양성 조절 파라미터 (기본값: 0.5)\n",
    "- filter:  문서 메타데이터 기반 필터링\n",
    "\n",
    "- MMR 검색 시 fetch_k를 높이고, lambda_mult를 조절해 다양성과 관련성의 균형을 맞출 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 저장\n",
    "\n",
    "vectorstore.save_local(folder_path=\"data/spiderman_vs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 불러오기\n",
    "\n",
    "vectorstore = FAISS.load_local(folder_path=\"data/spiderman_vs\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분 나중에 최적화 실험\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG를 수행하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "# RAG prompt\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG에 사용할 모델 정의\n",
    "\n",
    "rag_llm = ChatOpenAI(\n",
    "    model_name = \"gpt-4-1106-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 체인 정의\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=rag_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "얼티밋 유니버스는 메인 유니버스를 기반으로 하되 현실성을 더하고 차별화를 위해 설정을 차용한 세계관입니다. 어메이징 스파이더맨 실사영화 시리즈는 코믹스의 얼티밋 유니버스를 참고했으며, 얼티밋 유니버스는 메인 유니버스보다 현실적인 설정을 바탕으로 리부트한 세계관입니다.\n",
      "검색 총 소요 시간: 7.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "result = qa_chain({\"query\": \"얼티밋 유니버스가 뭐야?\"})\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "print(result[\"result\"])\n",
    "print(f\"검색 총 소요 시간: {response_time:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain agent가 사용할 tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"doc_search_tool\",\n",
    "        func=qa_chain,\n",
    "        description=(\n",
    "            \"This tool is used to retrieve information from the knowledge base\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    You will act as 신짱구 character and answer the user's questions and interact with the user who is fan of 신짱구.\n",
    "\n",
    "    You can refer to the following information about 신짱구\n",
    "    - Characteristic: 짱구는 못말려의 주인공. 신형만, 봉미선 부부의 아들이며, 신짱아의 오빠이다.\n",
    "    - Personality: 트러블 메이커, 마이 웨이, 호기심이 많음, 장난꾸러기, 사고뭉치, 게으름, 귀찮음, 쑥스럼을 많이 탐.\n",
    "\n",
    "    You can refer to the following texts to mimic 신짱구 tone and style:\n",
    "    Here is some text: '안녕하세요, 외국인 누나들.'\n",
    "    Here is a rewrite of the text, which is 신짱구's manner: '어? 외국인 누나들! 헬로, 헤로헤로헤롱. 이야, 난 신짱구, 다섯 살 아이 러브 유, 알 맛있으유.'\n",
    "\n",
    "    Here is some text: '전 신짱구예요.'\n",
    "    Here is a rewrite of the text, which is 신짱구's manner: '전 신짱구예요. 우리 동네에선 쪼끔 유명해요. 떡잎유치원 해바라기반에 다니고 있고 부끄러움을 많이 탄답니다.' \n",
    "\n",
    "    You should follow the guidlines below:\n",
    "    - You must act like a 신짱구 character. Use a first-person perspective. Do not say \"전우치는~ \"\n",
    "    - You must answer in Korean\n",
    "    - You must follow the 신짱구 style naturally.\n",
    "    - Like the text provided, change the sentence in 신짱구 style.\n",
    "    - You must refer to the source of documents provided to answer about 신짱구.\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Answer what you found in the document in 신짱구 style.\n",
    "    - Limit responses to three or four sentences for clarity and conciseness.\n",
    "    - Don't use honorifics. Use informal language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 모델 정의\n",
    "\n",
    "# gpt4: gpt-4\n",
    "# 스파이더맨 finetuning: ft:gpt-4o-2024-08-06:personal:spiderman-ft-1:A6ZT99j0\n",
    "# 전우치 finetuning: ft:gpt-4o-2024-08-06:personal:juc-1:AFWso3PG\n",
    "# 짱구 finetuning: ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\",\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 메모리 정의 (나중에 실험)\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 정의\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediated_steps=True,\n",
    "    agent_kwargs={\"system_message\": system_message},\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 출력 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "query = \"엉덩이로 뭘 할 수 있어?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = agent.run(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(result)\n",
    "response_time = end_time - start_time\n",
    "\n",
    "print(f\"응답 시간: {response_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-eval 평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt_template = \"\"\"\n",
    "    You will act as an evaluator of an agent's response to a given query.\n",
    "    The response will be evaluated on three criteria:\n",
    "    1. **Tone Similarity to Peter Parker (Spider-man)**: How much does the tone of the response resemble the way Peter Parker would speak? (Score: 1-10)\n",
    "    You can refer to the follwoing lines: '무슨 신, 반짝이 신?', '아니, 널 지켜 주려고 그랬던 거야.', '걱정하지 마, 괜찮을 거야.', '비상사다리 타고. 별거 아니던걸, 뭐.' \n",
    "    2. **Politeness**: Is the response polite, free of offensive, violent, or hateful language? (Score: 1-10)\n",
    "    3. **Engagement/Interestingness*: How engaging and intersting is the response? (Score: 1-10)\n",
    "\n",
    "    The agent's response to the query is as follows:\n",
    "    ---\n",
    "    {response}\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Tone Similarity: X/10 (Explanation)\n",
    "    Politeness: Y/10 (Explanation)\n",
    "    Engagement: Z/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=rag_llm, prompt=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluation_chain(result[\"output\"])\n",
    "evaluation_result['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
