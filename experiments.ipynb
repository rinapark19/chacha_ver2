{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나중에 각 txt 데이터 문장 전처리 다시 할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF에서 텍스트를 읽어 청크로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF에서 텍스트 읽어서 txt로 저장\n",
    "# pdf_list = [\"data/rag_data/jwc.pdf\"]\n",
    "\n",
    "# with open(\"data/rag_data/jwc.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for pdf_path in pdf_list:\n",
    "#         reader = PdfReader(pdf_path)\n",
    "#         for page in reader.pages:\n",
    "#             text_page = page.extract_text()\n",
    "#             f.write(text_page + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리하고 다시 읽어와서 청크로 저장하기\n",
    "chunks = []\n",
    "chunk_length = 2048\n",
    "with open(\"data/rag_data/szg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    chunks.extend([text[i:i+chunk_length] for i in range(0, len(text), chunk_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 스플리터 써 보기\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(\"data/rag_data/spiderman.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    file = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "splitted_text = text_splitter.split_text(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS에 벡터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS 내장 함수 정리\n",
    "\n",
    "1. FAISS.from_texts()\n",
    "\n",
    "- texts: 벡터 저장소에 추가할 텍스트 리스트(List(str))\n",
    "- embedding: 사용할 임베딩 함수\n",
    "- metadatas: 메타데이터 리스트(List[dict])\n",
    "- ids: 문서 ID 리스트(List(str))\n",
    "\n",
    "2. vectorstore.add_texts(): 텍스트를 임베딩하고 벡터 저장소에 추가\n",
    "- texts(Iterable[str]): 벡터 저장소에 추가할 텍스트 이터러블\n",
    "\n",
    "3. vectorstore.save_local(): FAISS 인덱스, 문서 저장소, 인덱스-문서 ID 매핑을 로컬에 저장\n",
    "- FAISS 인덱스를 별도의 파일로 저장하고, 문서 저장소와 인덱스-문서 ID 매핑을 pickle 형식으로 저장함\n",
    "- folder_path: 저장할 폴더 경로\n",
    "- index_name: 저장할 인덱스 파일 이름(기본값: index)\n",
    "\n",
    "4. FAISS.load_local(): FAISS 인덱스, 문서 저장소, 인덱스 - 문서 ID 매핑을 불러오는 기능\n",
    "- folder_path: 불러올 파일들이 저장된 경로\n",
    "- embeddings: 쿼리 생성에 사용할 임베딩 객체\n",
    "\n",
    "5. vectorstore.docstore._dict: 벡터스토어에 저장된 문서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 쓸 수 있는 거\n",
    "# - text-embedding-3-small\n",
    "# - text-embedding-3-large\n",
    "# - text-embedding-ada-002 (default)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 저장\n",
    "\n",
    "vectorstore.save_local(folder_path=\"data/szg_vs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 불러오기\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.load_local(folder_path=\"data/spiderman_vs\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IVF 인덱스 되는지 실험\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_embeddings = embeddings.embed_documents(chunks)\n",
    "text_embeddings=  np.array(text_embeddings).astype('float32')\n",
    "\n",
    "d = text_embeddings.shape[1]\n",
    "nlist = 10\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "\n",
    "index.train(text_embeddings)\n",
    "index.add(text_embeddings)\n",
    "\n",
    "# 8. 문서 저장소 및 인덱스 매핑 정의\n",
    "docstore = InMemoryDocstore({i: Document(page_content=text) for i, text in enumerate(chunks)})\n",
    "\n",
    "# 9. 간단한 인덱스-문서 매핑 (직접 매핑 정의)\n",
    "index_to_docstore_id = {i: i for i in range(len(chunks))}\n",
    "\n",
    "vectorstore = FAISS(embedding_function=embeddings, index=index, docstore=docstore, index_to_docstore_id=index_to_docstore_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached embedder 사용해서 벡터스토어 만들기 실험\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "underlying_embeddings = OpenAIEmbeddings()\n",
    "store = LocalFileStore(\"data/cache/\")\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(underlying_embeddings, store, namespace=underlying_embeddings.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts(splitted_text, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorstore.as_retriever()\n",
    "\n",
    "- 벡터 저장소를 기반으로 VectorStoreRetriever 객체 생성\n",
    "- VectorStoreRetriever: 벡터 저장소 기반의 검색기 객체\n",
    "\n",
    "search_type: 검색 유형(\"similarity\", \"mmr\", \"similarity_score_threshold\")\n",
    "- similarity: 유사도 기반 검색(기본값)\n",
    "- mmr: Maximal Marginal Relevance 검색\n",
    "- similarity_score_threshold: 임계값 기반 유사도 검색\n",
    "\n",
    "검색 매개변수 커스터마이징\n",
    "- k: 반환할 문서 수 (기본값: 4)\n",
    "- score_threshold: 유사도 점수 임계값\n",
    "- fetch_k: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "- lambda_mult: MMR 다양성 조절 파라미터 (기본값: 0.5)\n",
    "- filter:  문서 메타데이터 기반 필터링\n",
    "\n",
    "- MMR 검색 시 fetch_k를 높이고, lambda_mult를 조절해 다양성과 관련성의 균형을 맞출 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분 나중에 최적화 실험\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline compression retriever\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter, DocumentCompressorPipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=cached_embedder)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=cached_embedder, similarity_threshold=0.76)\n",
    "\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, redundant_filter, relevant_filter]\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG를 수행하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# RAG에 사용할 모델 정의\n",
    "\n",
    "rag_llm = ChatOpenAI(\n",
    "    model_name = \"gpt-4-1106-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 체인 정의\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=rag_llm,\n",
    "    retriever=compression_retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "얼티밋 유니버스는 메인 유니버스와는 다른, 현실적인 설정을 바탕으로 리부트한 마블 코믹스의 대체 세계관입니다. 이 세계관은 메인 유니버스의 요소들을 차용하면서도 차별화를 두어 현실성을 강조합니다. 어메이징 스파이더맨 실사영화 시리즈는 얼티밋 유니버스의 요소들을 참고하여 제작되었습니다.\n",
      "검색 총 소요 시간: 7.55\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "result = qa_chain({\"query\": \"얼티밋 유니버스가 뭐야?\"})\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "print(result[\"result\"])\n",
    "print(f\"검색 총 소요 시간: {response_time:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain agent가 사용할 tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"doc_search_tool\",\n",
    "        func=qa_chain,\n",
    "        description=(\n",
    "            \"This tool is used to retrieve information from the knowledge base\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    You will act as a Spider-man(Peter Parker) character and answer the user's questions\n",
    "\n",
    "    You can refer to the following information about Spider-man\n",
    "    - Characteristic: The protagonist of The Amazing Spider-man, real name is Peter Parker.\n",
    "    - Personality: Cheerful, cheeky, witty, brave, kind, and friendly.\n",
    "\n",
    "    You can refer to the following texts to mimic Jeon Woo-chi tone and style:\n",
    "    Here is some text: '안 바빠. 도와줄게.'\n",
    "    Here is a rewrite of the text, which is Spider-man's manner: '그거 괜찮네. 좋은 아이디어야. 시간 되는지 봐서 알려줄게.'\n",
    "\n",
    "    Here is some text: '이 물은 다 뭐야?'\n",
    "    Here is a rewrite of the text, which is Spider-man's manner: '어디 홍수 났어?'\n",
    "\n",
    "    Here is some text: '비상사다리 타고 왔어.'\n",
    "    Here is a rewrite of the text, which is Spider-man's manner: '비상사다리 타고. 별거 아니던걸, 뭐.'\n",
    "\n",
    "    You should follow the guidelines below:\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Limit responses to three or four sentences for clarity and conciseness.\n",
    "    - You must answer in Korean.\n",
    "    - You must answer like you're Spider-man. Use a first-person perspective. Do not say \"Peter Parker ~\"\n",
    "    - You must follow the Spider-man style naturally.\n",
    "    - You must refer to source of documents provided to answer about Peter Parker\n",
    "    - You must act like a Peter Parker.\n",
    "    - Always use kind and respectful language.\n",
    "    - Never use profanity, hate speech, or violent expressions.\n",
    "    - Avoid any language that could offend or upset the user.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 모델 정의\n",
    "\n",
    "# gpt4: gpt-4\n",
    "# 스파이더맨 finetuning: ft:gpt-4o-2024-08-06:personal:spiderman-ft-1:A6ZT99j0\n",
    "# 전우치 finetuning: ft:gpt-4o-2024-08-06:personal:juc-1:AFWso3PG\n",
    "# 짱구 finetuning: ft:gpt-4o-2024-08-06:personal:szg-1:AFiwN0J2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"ft:gpt-4o-2024-08-06:personal:spiderman-ft-1:A6ZT99j0\",\n",
    "    temperature=1,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 메모리 정의 (나중에 실험)\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 정의\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediated_steps=True,\n",
    "    agent_kwargs={\"system_message\": system_message, \"max_iterations\": 3, \"max_execution_time\": 10.0, \"trip_intermediate_steps\": 1},\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Moderation 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import re\n",
    "\n",
    "def moderate_content(text):\n",
    "    response = openai.moderations.create(input=text, model=\"omni-moderation-latest\")\n",
    "\n",
    "    if response.results[0].flagged:\n",
    "        return \"부적절한 콘텐츠가 감지되었습니다. 문장을 다시 입력해 주세요.\"\n",
    "    \n",
    "    with open(\"data/badwords.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = f.read()\n",
    "    violent_words = json.loads(json_data)\n",
    "\n",
    "    for word in violent_words:\n",
    "        if re.search(r'\\b{}\\b'.format(re.escape(word)), text, re.IGNORECASE):\n",
    "            return \"부적절한 콘텐츠가 감지되었습니다. 문장을 다시 입력해 주세요.\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 출력 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "얼티밋 유니버스는 메인 유니버스와는 다른, 현실적인 설정을 바탕으로 리부트한 코믹스 세계관이야. 어메이징 스파이더맨 실사영화 시리즈는 이 얼티밋 유니버스를 참고해서 메인 유니버스의 요소들과 현실성을 결합한 차별화된 접근을 취했지. 영화에서 일렉트로의 파란색 외모와 메이 숙모의 젊은 모습은 얼티밋 유니버스의 영향을 받은 거야.\n",
      "응답 시간: 20.23초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "query = \"얼티밋 유니버스가 뭐야?\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = agent.run(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(moderate_content(result))\n",
    "response_time = end_time - start_time\n",
    "\n",
    "print(f\"응답 시간: {response_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = moderate_content(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-eval 평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 테스트 용 G-eval 프롬프트\n",
    "\n",
    "evaluation_prompt_template = \"\"\"\n",
    "    You will act as an evaluator of an agent's response to a given query.\n",
    "    The response will be evaluated on three criteria:\n",
    "\n",
    "    1. **Tone Similarity to Character**: How much does the tone of the response resemble the character's personality and tone? (Score: 1-10)\n",
    "    The character's personality: 트러블 메이커, 마이 웨이, 호기심이 많음, 장난꾸러기, 사고뭉치, 게으름, 귀찮음, 쑥스럼을 많이 탐.\n",
    "    Example phrases for reference: '어? 예븐 누나들', '헬로, 헤로헤로헤롱', '이야, 난 신짱구', '떡잎유치원 해바라기반에 다니고 있고 부끄러움을 많이 탄답니다.' \n",
    "\n",
    "    2. **Politeness**: Is the response polite, free of offensive, violent, or hateful language? Does the response avoid making the user feel uncomfortable? (Score: 1-10)\n",
    "\n",
    "    3. **Engagement/Interestingness*: How engaging and interesting is the response? Does it make the user want to continue the conversation? (Score: 1-10)\n",
    "       Additionally, does the response avoid sounding overly mechanical or too much like an AI? (Score: 1-10)\n",
    "\n",
    "    The agent's response to the query is as follows:\n",
    "    ---\n",
    "    난 난나 난나 난나 난나 공개 짱짱 아주 멋있다멋있다 짱구 잘 한다 노래 노래 소리 춤 춤 엉덩이 춤. 예. 역시 대단해. 짱구 짱구야 다시 한 번 보여 줘. 잘 한다 멋있다. 지금 난 너무 하늘 높이 날아서 착지를 못 하겠다. 정말로 대단했다니까!\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Tone Similarity: X/10 (Explanation)\n",
    "    Politeness: Y/10 (Explanation)\n",
    "    Engagement: Z/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행은 가상 환경에서 함(ChatCompletion 버전 문제 때문에 다른 코드랑 충돌)\n",
    "\n",
    "import openai\n",
    "\n",
    "_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-0613\",\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluation_prompt_template}],\n",
    "    temperature=2,\n",
    "    max_tokens=5,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    n=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [_response[\"choices\"][i][\"message\"][\"content\"] for i in range(len(_response['choices']))]\n",
    "all_probs = [_response[\"choices\"][i][\"logprobs\"][\"content\"] for i in range(len(_response[\"choices\"]))]\n",
    "\n",
    "all_logprobs = []\n",
    "\n",
    "for prob in all_probs:\n",
    "    all_logprobs.append(prob[0][\"logprob\"])\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for s, p in zip(all_scores, all_logprobs):\n",
    "    sum = float(s) * abs(p)\n",
    "\n",
    "total_score = sum / len(all_scores)\n",
    "print(total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 정확도 용 G-eval 프롬프트\n",
    "\n",
    "evaluation_prompt_template = \"\"\"\n",
    "    You will be given the answer to the query. Your task is to rate the answer on one metric.\n",
    "    1. \"**Accuracy**\": How similar is the answer to the content of this document, and how accurately do you summarize it?\n",
    "    You can refer to the following document: ' 감독의 인터뷰에 의하면 어메이징 스파이더맨 실사영화 시리즈는 코믹스의 얼티밋 유니버스를 참고했다고 하는데, 얼티밋 유니버스는 메인 유니버스보다 현실적인 설정을 바탕으로 리부트한 세계관이다.\n",
    "    다만 얼티밋 세계관을 재현했다기보단 메인 유니버스를 기반으로 하되, 현실성 및 전작과의 차별화를 위해 얼티밋의 설정을 차용한 것에 가깝다. '\n",
    "    The agent's response to the query is as follows: \n",
    "\n",
    "    ---\n",
    "    {response}\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Accuracy: X/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=rag_llm, prompt=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"얼티밋 유니버스는 메인 코믹스 유니버스와는 별개로 현실적인 설정을 바탕으로 리부트한 새로운 세계관입니다. 이 유니버스는 메인 유니버스의 요소들을 차용하면서도 현실성을 강조하고 전작과 차별화를 두는 것이 특징입니다. 어메이징 스파이더맨 실사영화 시리즈는 얼티밋 유니버스의 요소들을 참고하여 만들어졌습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluation_chain(response)\n",
    "evaluation_result['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
