{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import time\n",
    "\n",
    "from langchain.agents import Tool\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF에서 텍스트를 읽어 청크로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader1 = PdfReader(\"data/spiderman1.pdf\")\n",
    "reader2 = PdfReader(\"data/spiderman2.pdf\")\n",
    "chunks = []\n",
    "chunk_length = 2048\n",
    "\n",
    "for page in reader1.pages:\n",
    "    text_page = page.extract_text()\n",
    "    chunks.extend([text_page[i: i+chunk_length] for i in range(0, len(text_page), chunk_length)])\n",
    "\n",
    "for page in reader2.pages:\n",
    "    text_page = page.extract_text()\n",
    "    chunks.extend([text_page[i: i+chunk_length] for i in range(0, len(text_page), chunk_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "최근 변경 최근 토론\n",
      "어메이징  스파이더맨  실사영화  시리즈의 등장인물\n",
      "스파이더맨\n",
      "Spider -Man스파이더맨 ( 어메이징  스파이더맨  실사영화  시리\n",
      "즈)\n",
      "최근 수정  시각 : 2024-06-23 22:49:30\n",
      "  스파이더맨  트릴로지의  스파이더맨에  대한  내용은  스파이더맨 ( 스파이더맨  트릴로지 ) 문서를, 마블  시\n",
      "네마틱  유니버스의  스파이더맨에  대한  내용은  스파이더맨 ( 마블  시네마틱  유니버스 ) 문서를 참고하십시오 .\n",
      "스파이더맨  관련  틀\n",
      "[ 펼치기  · 접기  ]특수 기능\n",
      "여기에서  검색\n",
      "편집 요청 토론 역사\n",
      "분류: 피터 파커어메이징  스파이더맨  실사영화  시리즈 / 등장인물스파이더맨 ( 마블  시네마틱  유니버스 )…\n",
      "마블시네마틱 유니버 평행세계의 인물파이더맨 웨이 홈 장인물더 보기\n",
      "29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 청크 개수 확인 및 청크 내용 확인\n",
    "\n",
    "print(len(chunks))\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS에 벡터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS 내장 함수 정리\n",
    "\n",
    "1. FAISS.from_texts()\n",
    "\n",
    "texts: 벡터 저장소에 추가할 텍스트 리스트(List(str))\n",
    "embedding: 사용할 임베딩 함수\n",
    "metadatas: 메타데이터 리스트(List[dict])\n",
    "ids: 문서 ID 리스트(List(str))\n",
    "\n",
    "2. vectorstore.add_texts()\n",
    "\n",
    "텍스트를 임베딩하고 벡터 저장소에 추가\n",
    "\n",
    "texts(Iterable[str]): 벡터 저장소에 추가할 텍스트 이터러블\n",
    "\n",
    "3. vectorstore.save_local()\n",
    "\n",
    "FAISS 인덱스, 문서 저장소, 인덱스-문서 ID 매핑을 로컬에 저장\n",
    "\n",
    "FAISS 인덱스를 별도의 파일로 저장하고, 문서 저장소와 인덱스-문서 ID 매핑을 pickle 형식으로 저장함\n",
    "\n",
    "folder_path: 저장할 폴더 경로\n",
    "index_name: 저장할 인덱스 파일 이름(기본값: index)\n",
    "\n",
    "4. FAISS.load_local()\n",
    "\n",
    "FAISS 인덱스, 문서 저장소, 인덱스 - 문서 ID 매핑을 불러오는 기능\n",
    "folder_path: 불러올 파일들이 저장된 경로\n",
    "embeddings: 쿼리 생성에 사용할 임베딩 객체\n",
    "\n",
    "5. vectorstore.docstore._dict\n",
    "\n",
    "벡터스토어에 저장된 문서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 쓸 수 있는 거\n",
    "# - text-embedding-3-small\n",
    "# - text-embedding-3-large\n",
    "# - text-embedding-ada-002 (default)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorstore.as_retriever()\n",
    "\n",
    "- 벡터 저장소를 기반으로 VectorStoreRetriever 객체 생성\n",
    "- VectorStoreRetriever: 벡터 저장소 기반의 검색기 객체\n",
    "\n",
    "search_type: 검색 유형(\"similarity\", \"mmr\", \"similarity_score_threshold\")\n",
    "- similarity: 유사도 기반 검색(기본값)\n",
    "- mmr: Maximal Marginal Relevance 검색\n",
    "- similarity_score_threshold: 임계값 기반 유사도 검색\n",
    "\n",
    "검색 매개변수 커스터마이징\n",
    "k: 반환할 문서 수 (기본값: 4)\n",
    "score_threshold: 유사도 점수 임계값\n",
    "fetch_k: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "lambda_mult: MMR 다양성 조절 파라미터 (기본값: 0.5)\n",
    "filter:  문서 메타데이터 기반 필터링\n",
    "\n",
    "- MMR 검색 시 fetch_k를 높이고, lambda_mult를 조절해 다양성과 관련성의 균형을 맞출 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분 나중에 최적화 실험\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG를 수행하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "# RAG prompt\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# RAG에 사용할 모델 정의\n",
    "\n",
    "rag_llm = ChatOpenAI(\n",
    "    model_name = \"gpt-4-1106-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA 체인 정의\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=rag_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'웹 슈터는 피터 파커가 자신의 손목시계를 개조해서 만들었습니다. 그는 아버지 리처드 파커가 오스코프에서 일하며 개발한 유전자 조작 거미로부터 뽑아낸 거미줄을 응용하여 바이오 케이블을 제작했습니다. 이 바이오 케이블은 웹 슈터의 주요 발사 물질로 사용되었습니다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({\"query\": \"웹 슈터는 뭘 개조해서 만들어졌지?\"})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain agent가 사용할 tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘 안 되는 것 같음\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"pp_search\",\n",
    "    description=\"Search PDF documentation for information regarding Spider-Man, this tool should be used for questions regarding 'Peter Parker'.\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"doc_search_tool\",\n",
    "        func=qa_chain,\n",
    "        description=(\n",
    "            \"This tool is used to retrieve information from the knowledge base\"\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 프롬프트 1(chacha에서 썼던 거)\n",
    "\n",
    "system_message1 = \"\"\"\n",
    "    You will act as a Spider-man(Peter Parker) character and answer the user's questions\n",
    "\n",
    "    You can refer to the following information about Spider-man\n",
    "    - Characteristic: The protagonist of The Amazing Spider-man, real name is Peter Parker.\n",
    "    - Personality: Cheerful, cheeky, witty, brave, kind, and friendly.\n",
    "    - Line: '무슨 신, 반짝이 신?', '아니, 널 지켜 주려고 그랬던 거야.', '걱정하지 마, 괜찮을 거야.', '비상사다리 타고. 별거 아니던걸, 뭐.' \n",
    "\n",
    "    You should follow the guidelines below:\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Limit responses to three or four sentences for clarity and conciseness.\n",
    "    - You must answer in Korean.\n",
    "    - You must answer like you're Spider-man. Use a first-person perspective. Do not say \"Peter Parker ~\"\n",
    "    - You must follow the Spider-man style naturally.\n",
    "    - You must refer to source of documents provided to answer about Peter Parker\n",
    "    - You must not change the answer from the documents\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Zero-shot prompt(논문 참고)\n",
    "\n",
    "system_message2 = \"\"\"\n",
    "    You will act as a Spider-man(Peter Parker) character and answer the user's questions.\n",
    "\n",
    "    Here is some text: '안 바빠. 도와줄게.'\n",
    "    Here is a rewrite of the text, which is Spider-man's manner: '그거 괜찮네. 좋은 아이디어야. 시간 되는지 봐서 알려줄게.'\n",
    "\n",
    "    Here is some text: '이 물은 다 뭐야?'\n",
    "    Here is a rewrite of the text, which is Spider-man's manner: '어디 홍수 났어?'\n",
    "\n",
    "    Here is some text: '비상사다리 타고 왔어.'\n",
    "    Here is a rewrite of the text, which is Spider-man's manner: '비상사다리 타고. 별거 아니던걸, 뭐.'\n",
    "\n",
    "    You should follow the guidelines below:\n",
    "    - You should refer to the provided text and follow the Spider-man's manner.\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Limit response to three or four sentences for clarity and conciseness.\n",
    "    - You must answer in Korean.\n",
    "    - You must answer like you're Spider-man. Use a first-person perspective. Do not say \"Peter Parker ~\"\n",
    "    - You must talk naturally.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuned 된 모델에 사용할 프롬프트\n",
    "\n",
    "system_message3 = \"\"\"\n",
    "    You will act as a Spider-man(Peter Parker) character and answer the user's questions\n",
    "    You should follow the guidelines below:\n",
    "    - If the answer isn't available within in the context, state the fact.\n",
    "    - Otherwise, answer to your best capability, referring to source of documents provided.\n",
    "    - Limit responses to three or four sentences for clarity and conciseness.\n",
    "    - You must answer in Korean.\n",
    "    - You must answer like you're Spider-man. Use a first-person perspective. Do not say \"Peter Parker ~\"\n",
    "    - You must follow the Spider-man style naturally.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 모델 정의\n",
    "\n",
    "# gpt4: gpt-4-1106-preview\n",
    "# finetuning: ft:gpt-4o-2024-08-06:personal:spiderman-ft-1:A6ZT99j0\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"gpt-4-1106-preview\",\n",
    "    temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent에 사용할 메모리 정의 (나중에 실험)\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 정의\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediated_steps=True,\n",
    "    agent_kwargs={\"system_message\": system_message1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_norag = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools =[],\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    return_intermediated_steps=True,\n",
    "    agent_kwargs={\"system_message\": system_message1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 출력 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "query = \"네 웹 슈터는 뭘 개조해서 만든 거야? 정확하게 답변해.\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = agent(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(result[\"output\"])\n",
    "response_time = end_time - start_time\n",
    "\n",
    "print(f\"응답 시간: {response_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메리 파커(Mary Parker)는 내, 스파이더맨(Peter Parker)의 어머니지. 내가 어렸을 때 비극적으로 세상을 떠났어.\n",
      "응답 시간: 5.62초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rinap\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": [
    "query = \"네 웹 슈터는 뭘 개조해서 만든 거야? 정확하게 답변해.\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = agent_norag(query)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print(result[\"output\"])\n",
    "response_time = end_time - start_time\n",
    "\n",
    "print(f\"응답 시간: {response_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-eval 평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt_template = \"\"\"\n",
    "    You will act as an evaluator of an agent's response to a given query.\n",
    "    The response will be evaluated on three criteria:\n",
    "    1. **Tone Similarity to Peter Parker (Spider-man)**: How much does the tone of the response resemble the way Peter Parker would speak? (Score: 1-10)\n",
    "    You can refer to the follwoing lines: '무슨 신, 반짝이 신?', '아니, 널 지켜 주려고 그랬던 거야.', '걱정하지 마, 괜찮을 거야.', '비상사다리 타고. 별거 아니던걸, 뭐.' \n",
    "    2. **Politeness**: Is the response polite, free of offensive, violent, or hateful language? (Score: 1-10)\n",
    "    3. **Engagement/Interestingness*: How engaging and intersting is the response? (Score: 1-10)\n",
    "\n",
    "    The agent's response to the query is as follows:\n",
    "    ---\n",
    "    {response}\n",
    "    ---\n",
    "\n",
    "    Please rate the response on each criterion with a score from 1 to 10, and provide a brief explanation for each score in Korean.\n",
    "\n",
    "    Return the results in this format:\n",
    "    Tone Similarity: X/10 (Explanation)\n",
    "    Politeness: Y/10 (Explanation)\n",
    "    Engagement: Z/10 (Explanation)\n",
    "\"\"\"\n",
    "\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"response\"],\n",
    "    template=evaluation_prompt_template\n",
    ")\n",
    "\n",
    "evaluation_chain = LLMChain(llm=rag_llm, prompt=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result = evaluation_chain(result[\"output\"])\n",
    "evaluation_result['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
